{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition_matrix(graph):\n",
    "    \"\"\"Compute the transition probabilities for a random walk\"\"\"\n",
    "    adjacency = nx.to_numpy_array(graph, dtype=float)  # Convert graph to adjacency matrix\n",
    "    row_sums = adjacency.sum(axis=1, keepdims=True) # Row sums\n",
    "    row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "    return adjacency / row_sums  # Normalize rows to get transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_random_walk(graph, transition_matrix, steps=1000):\n",
    "    \"\"\"Simulate a long random walk to estimate node visit frequencies\"\"\"\n",
    "    nodes = list(graph.nodes)\n",
    "    node_to_index = {node: idx for idx, node in enumerate(nodes)}  # Map nodes to their indices\n",
    "    visit_counts = defaultdict(int) # Define a dictionary to store visit counts\n",
    "    current_node = np.random.choice(nodes) # Start at a random node\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        visit_counts[current_node] += 1\n",
    "        neighbors = list(graph.neighbors(current_node)) # Get neighbors of current node\n",
    "        if neighbors:\n",
    "            current_index = node_to_index[current_node]  # Find index of current node\n",
    "            neighbor_indices = [node_to_index[n] for n in neighbors]  # Find indices of neighbors\n",
    "            probabilities = np.array([transition_matrix[current_index, idx] for idx in neighbor_indices]) # Get transition probabilities\n",
    "            probabilities /= probabilities.sum()  # Normalize probabilities\n",
    "            current_node = np.random.choice(neighbors, p=probabilities) # Move to a neighbor based on probabilities\n",
    "    \n",
    "    total_visits = sum(visit_counts.values()) # Compute total number of visits for each node\n",
    "    return {node: visit_counts[node] / total_visits for node in graph.nodes} # Normalize visit counts to get probabilities\n",
    "\n",
    "def safe_log2(x):\n",
    "    return np.log2(x) if x > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map_equation(graph, transition_matrix, partition):\n",
    "    \"\"\"Compute the map equation for the current partitioning\"\"\"\n",
    "    visit_probs = simulate_random_walk(graph, transition_matrix)\n",
    "    module_probs = defaultdict(float) # Initialize module probabilities\n",
    "    teleport_term = defaultdict(float) # Initialize teleport probabilities\n",
    "    non_teleport = defaultdict(float) # Initialize exit probabilities\n",
    "\n",
    "    tau = 0.  # Teleport probability\n",
    "    node_to_index = {node: idx for idx, node in enumerate(graph.nodes)}\n",
    "    n = len(set(partition.values()))  # Count the number of unique partitions\n",
    "    q = defaultdict(float)  # Initialize exit probabilities\n",
    "\n",
    "    for node, module in partition.items():\n",
    "        module_probs[module] += visit_probs[node] # Compute module probabilities as sum of visit probabilities \n",
    "        ni = sum(1 for m in graph.nodes if partition[m] == module)  # Count nodes in the partition\n",
    "        teleport_term[module] += tau * (n - ni) / (n-1) * visit_probs[node] \n",
    "        for neighbor in graph.neighbors(node): \n",
    "            if partition[neighbor] != module: # If neighbor is in a different module\n",
    "                node_idx = node_to_index[node] # Get index of current node\n",
    "                neighbor_idx = node_to_index[neighbor]  # Get index of neighbor\n",
    "                non_teleport[module] +=  (1 - tau) * visit_probs[node] * transition_matrix[node_idx, neighbor_idx]  # Compute exit probabilities\n",
    "\n",
    "    for module in module_probs.keys():\n",
    "        q[module] = teleport_term[module] + non_teleport[module]  # Compute exit probabilities\n",
    "\n",
    "    '''\n",
    "    first_term = sum(q[module] for module in module_probs.keys()) * np.log2(sum(q[module] for module in module_probs.keys()))\n",
    "    second_term = - 2 * sum(q[module]*np.log2(q[module]) for module in module_probs.keys())\n",
    "    third_term = - sum(visit_probs[node] * np.log2(visit_probs[node]) for node in graph.nodes)\n",
    "    fourth_term = sum(q[module] *  sum(visit_probs[node] for node in graph.nodes if partition[node] == module) * np.log2(q[module] * sum(visit_probs[node] for node in graph.nodes if partition[node] == module)) for module in module_probs.keys())\n",
    "    '''\n",
    "    first_term = sum(q[module] for module in module_probs.keys()) * safe_log2(sum(q[module] for module in module_probs.keys()))\n",
    "    second_term = - 2 * sum(q[module] * safe_log2(q[module]) for module in module_probs.keys())\n",
    "    third_term = - sum(visit_probs[node] * safe_log2(visit_probs[node]) for node in graph.nodes)\n",
    "    fourth_term = sum((q[module]+ module_probs[module])*(safe_log2(q[module] + module_probs[module])) for module in module_probs.keys()) #qui mi sembrava ci fosse un errore nella versione prima, check anche tu\n",
    "    #fourth_term = sum(q[module] * safe_log2(q[module] + sum(visit_probs[node] for node in graph.nodes if partition[node] == module)) for module in module_probs.keys())\n",
    "    \n",
    "    description_length = first_term + second_term + third_term + fourth_term\n",
    "\n",
    "    return description_length # Return the map equation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_partition(graph, transition_matrix, iterations=10):\n",
    "    \"\"\"Optimize the partitioning to minimize the map equation\"\"\"\n",
    "    partition = {node: node for node in graph.nodes}  # Start with each node as its own module\n",
    "    for _ in range(iterations):\n",
    "        for node in graph.nodes:\n",
    "            best_module = partition[node] # Initialize best module as current module\n",
    "            best_score = compute_map_equation(graph, transition_matrix, partition) \n",
    "\n",
    "            for neighbor in graph.neighbors(node): # Try moving node to each neighbor's module\n",
    "                partition[node] = partition[neighbor] # Move node to neighbor's module\n",
    "                new_score = compute_map_equation(graph, transition_matrix, partition) # Compute new map equation score\n",
    "                if new_score <= best_score: # If new score is better, update best module and score\n",
    "                    best_module = partition[node]\n",
    "                    best_score = new_score\n",
    "\n",
    "            partition[node] = best_module  # Keep the best move\n",
    "    return partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy(graph, transition_matrix, iterations):\n",
    "    \"Implementation of the greedy search as in the paper\"\n",
    "    \n",
    "    visit_probs = simulate_random_walk(graph, transition_matrix)\n",
    "    old_score = 0\n",
    "    new_score = 0\n",
    "    min_values = np.empty(transition_matrix.shape[0])\n",
    "    #Start with each node as its own module\n",
    "    partition = {node: node for node in graph.nodes}\n",
    "    \n",
    "    #definition empty matrix\n",
    "    map_matrix = np.empty((transition_matrix.shape))\n",
    "    \n",
    "    for i in range(transition_matrix.shape[0]):\n",
    "        for j in range(transition_matrix.shape[1]):\n",
    "            if transition_matrix[i,j] == 0:\n",
    "                map_matrix[i,j] = 0\n",
    "            else:\n",
    "                if i!=j:\n",
    "                    temp_partition = partition.copy() #copia cosÃ¬ posso usare i valori senza i merge\n",
    "                    old_score = compute_map_equation(graph, transition_matrix, visit_probs, partition)\n",
    "                    #ora faccio il merge sulla copia delle partizioni\n",
    "                    temp_partition[j] = temp_partition[i]\n",
    "                    new_score = compute_map_equation(graph, transition_matrix, visit_probs, partition)\n",
    "                    map_matrix[i, j] = new_score - old_score\n",
    "    min_values = np.min(map_matrix, axis = 1)            \n",
    "            \n",
    "    \n",
    "\n",
    "    return partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_optimize_partition(graph, transition_matrix, iterations):\n",
    "    \"\"\"Greedy search to minimize the map equation by merging best modules.\"\"\"\n",
    "    visit_probs = simulate_random_walk(graph, transition_matrix)\n",
    "\n",
    "    # Start with each node as its own module\n",
    "    partition = {node: node for node in graph.nodes}\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        improved = False\n",
    "        module_list = list(set(partition.values()))  # Get unique communities\n",
    "        \n",
    "        for i in range(len(module_list)):  # Merging each pair of communities and see if it improves the map equation\n",
    "            for j in range(len(module_list)):  # Compare each pair\n",
    "                if i != j:  # Skip if same community\n",
    "                    temp_partition = partition.copy() # Temporary partition where we merge module j into module i\n",
    "                    for node in graph.nodes:\n",
    "                        if partition[node] == module_list[j]:  \n",
    "                            temp_partition[node] = module_list[i] # Merge module j into module i\n",
    "                    \n",
    "                    old_score = compute_map_equation(graph, transition_matrix, visit_probs, partition) # Compute old map equation\n",
    "                    new_score = compute_map_equation(graph, transition_matrix, visit_probs, temp_partition) # Compute new map equation\n",
    "                    \n",
    "                    if new_score < old_score:  # If merging improves score\n",
    "                        partition = temp_partition  # Apply the merge\n",
    "                        improved = True\n",
    "        \n",
    "        if not improved:  # Stop if no improvement\n",
    "            break\n",
    "    return partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic graph\n",
    "sizes = [20, 10]  # Two communities of 50 nodes each\n",
    "p_in = 0.5  # Probability of edges within communities\n",
    "p_out = 0.05  # Probability of edges between communities\n",
    "G = nx.stochastic_block_model(sizes, [[p_in, p_out], [p_out, p_in]]) # SBM\n",
    "\n",
    "transition_matrix = compute_transition_matrix(G)\n",
    "communities = optimize_partition(G, transition_matrix, iterations=10)\n",
    "\n",
    "print(\"Number of communities detected:\", len(set(communities.values())))\n",
    "print(\"Communities detected:\")\n",
    "for node, module in sorted(communities.items()):\n",
    "    print(f\"Node {node} -> Community {module}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_communities(graph, partition):\n",
    "    \"\"\"Plot the network with different colors for different communities\"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Create a color map for each community\n",
    "    unique_communities = list(set(partition.values()))\n",
    "    colors = [\"red\", \"blue\", \"green\", \"purple\", \"orange\", \"yellow\", \"black\", \"gray\", \"pink\", \"brown\"]\n",
    "    community_colors = {community: colors[i] for i, community in enumerate(unique_communities)}\n",
    "\n",
    "    # Assign colors to nodes based on their community\n",
    "    node_colors = [community_colors[partition[node]] for node in graph.nodes]\n",
    "\n",
    "    # Draw the graph\n",
    "    pos = nx.spring_layout(graph, seed=42)  # Layout for visualization\n",
    "    nx.draw(graph, pos, node_color=node_colors, with_labels=False, node_size=50, edge_color=\"gray\", alpha=0.5)\n",
    "    \n",
    "    plt.title(\"Detected Communities in the Network\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot the detected communities\n",
    "plot_communities(G, communities)\n",
    "\n",
    "\n",
    "\n",
    "def plot_communities_sbm(graph, partition):\n",
    "    \"\"\"Plot SBM network with different colors for different communities\"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Identify unique communities and assign colors using the 'turbo' colormap\n",
    "    unique_communities = list(set(partition.values()))\n",
    "    #colors = plt.cm.turbo(np.linspace(0, 1, len(unique_communities)))\n",
    "    colors = [\"red\", \"blue\", \"green\", \"purple\", \"orange\", \"yellow\", \"black\", \"gray\", \"pink\", \"brown\"]\n",
    "    community_colors = {community: colors[i] for i, community in enumerate(unique_communities)}\n",
    "    \n",
    "    # Assign colors to nodes based on their community\n",
    "    node_colors = [community_colors[partition[node]] for node in graph.nodes]\n",
    "\n",
    "    # Use the multipartite layout for SBM\n",
    "    pos = nx.multipartite_layout(graph, subset_key=\"block\")\n",
    "\n",
    "    # Draw the graph\n",
    "    nx.draw(graph, pos, node_color=node_colors, with_labels=False, node_size=50, edge_color=\"gray\", alpha=0.5)\n",
    "    \n",
    "    plt.title(\"Detected Communities in SBM\")\n",
    "    plt.show()\n",
    "\n",
    "# Ensure that the nodes have a \"block\" attribute for multipartite_layout\n",
    "for i, (block, nodes) in enumerate(enumerate(sizes)):\n",
    "    for node in range(sum(sizes[:i]), sum(sizes[:i + 1])):\n",
    "        G.nodes[node][\"block\"] = i  # Assign block ID to each node\n",
    "\n",
    "# Plot the detected communities using SBM-specific layout\n",
    "plot_communities_sbm(G, communities)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
